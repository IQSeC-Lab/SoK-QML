# -*- coding: utf-8 -*-
"""MLP_DeepFool

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1775NpIyxsumiUWyORcCib3wP_yZIvAXR
"""



# Importing necessary libraries for PyTorch implementation
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from sklearn.metrics import accuracy_score, precision_score
import matplotlib.pyplot as plt
import numpy as np
import time

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

if device.type == 'cuda':
    print(torch.cuda.get_device_name(0))

# Define transformations
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])

# Load MNIST data
train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)

# Define MLP model
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.flatten = nn.Flatten()
        self.model = nn.Sequential(
            nn.Linear(28*28, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.flatten(x)
        return self.model(x)

# Instantiate model, define loss function and optimizer
model = MLP().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training function
def train(model, loader, criterion, optimizer, epochs=15):
    model.train()
    train_losses = []
    start_time = time.time()
    for epoch in range(epochs):
        total_loss = 0
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        avg_loss = total_loss / len(loader)
        train_losses.append(avg_loss)
    runtime = time.time() - start_time
    return train_losses, runtime

# Train the model
train_losses, runtime = train(model, train_loader, criterion, optimizer)

#save the trained model
torch.save(model.state_dict(), 'mlp_mnist_model.pth')



def evaluate(model, loader):
    model.eval()
    y_true, y_pred = [], []
    with torch.no_grad():
        for data, target in loader:
            data = data.to(device)
            output = model(data)
            preds = output.argmax(dim=1).cpu().numpy()
            y_pred.extend(preds)
            y_true.extend(target.numpy())
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    return accuracy, precision, y_true, y_pred

# Evaluate model
accuracy, precision, y_true, y_pred = evaluate(model, test_loader)

#load the previously trained model

# Re-create the model architecture
model = MLP().to(device)

# Load the saved weights
model.load_state_dict(torch.load('mlp_mnist_model.pth', map_location=device))

# Set the model to evaluation mode
model.eval()

# Plot sample predictions
fig, axes = plt.subplots(1, 5, figsize=(12, 3))
for i, ax in enumerate(axes):
    ax.imshow(test_dataset[i][0].reshape(28,28), cmap='gray')
    ax.set_title(f"Pred: {y_pred[i]}, True: {y_true[i]}")
    ax.axis('off')
plt.show()

# Plot training loss
plt.figure(figsize=(8,4))
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# Display metrics
accuracy, precision, runtime





pip install torchattacks

# Instantiate DeepFool attack
import torch
import torchattacks

deepfool_attack = torchattacks.DeepFool(model, steps=50)

def generate_adversarial_examples(model, loader, attack, num_samples=1000):
    model.eval()
    adv_examples, orig_labels = [], []

    for data, target in loader:
        data, target = data.to(device), target.to(device)

        # Ensure data tracks gradients
        data.requires_grad = True

        # Generate adversarial examples
        adv_data = attack(data, target)

        adv_examples.append(adv_data.detach().cpu())
        orig_labels.append(target.cpu())

        if len(torch.cat(adv_examples)) >= num_samples:
            break

    adv_examples = torch.cat(adv_examples)[:num_samples]
    orig_labels = torch.cat(orig_labels)[:num_samples]

    return adv_examples, orig_labels

# Function to generate adversarial examples
adv_examples, orig_labels = generate_adversarial_examples(model, test_loader, deepfool_attack, num_samples=1000)

from sklearn.metrics import accuracy_score, precision_score

def evaluate_model_on_adversarial(model, adv_examples, orig_labels):
    model.eval()

    with torch.no_grad():
        outputs = model(adv_examples.to(device))
        preds = outputs.argmax(dim=1).cpu().numpy()
        labels = orig_labels.numpy()

        accuracy = accuracy_score(labels, preds)
        precision = precision_score(labels, preds, average='weighted')

    return accuracy, precision, labels, preds

# Evaluate the model on adversarial examples
accuracy_adv, precision_adv, y_true_adv, y_pred_adv = evaluate_model_on_adversarial(model, adv_examples, orig_labels)

# Results
print(f"Accuracy after DeepFool attack: {accuracy_adv * 100:.2f}%")
print(f"Precision after DeepFool attack: {precision_adv * 100:.2f}%")

# Visualization of adversarial examples
fig, axes = plt.subplots(1, 5, figsize=(15, 3))
for i, ax in enumerate(axes):
    ax.imshow(adv_examples[i].squeeze(), cmap='gray')
    ax.set_title(f"Adv: {y_pred_adv[i]}, Orig: {y_true_adv[i]}")
    ax.axis('off')
plt.suptitle('DeepFool Adversarial Examples (MNIST)')
plt.show()

import numpy as np
import matplotlib.pyplot as plt

def perturbation_vs_accuracy(model, loader, attack, perturbation_bins):
    model.eval()
    perturbations = []
    correct = []

    for data, target in loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True

        # Generate adversarial examples
        adv_data = attack(data, target)

        # Compute perturbation magnitude (L2 norm)
        perturbation_batch = (adv_data - data).view(data.size(0), -1).norm(p=2, dim=1).detach().cpu().numpy()

        perturbations.extend(perturbation_batch)

        # Evaluate accuracy on adversarial data
        with torch.no_grad():
            output = model(adv_data)
            preds = output.argmax(dim=1)
            correct.extend((preds == target).cpu().numpy())

        if len(perturbations) >= 1000:
            break

    perturbations = np.array(perturbations)
    correct = np.array(correct)

    accuracy_per_bin = []
    bin_centers = []

    for i in range(len(perturbation_bins)-1):
        indices = (perturbations >= perturbation_bins[i]) & (perturbations < perturbation_bins[i+1])
        if indices.sum() > 0:
            accuracy = correct[indices].mean()
            accuracy_per_bin.append(accuracy * 100)  # percent
            bin_centers.append((perturbation_bins[i] + perturbation_bins[i+1]) / 2)

    return bin_centers, accuracy_per_bin

import torch.nn as nn

class RobustMLP(nn.Module):
    def __init__(self):
        super(RobustMLP, self).__init__()
        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        return self.model(x)

import torchattacks
import torch.optim as optim

model = RobustMLP().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Define DeepFool Attack
deepfool_attack = torchattacks.DeepFool(model, steps=10)

def adversarial_training(model, loader, criterion, optimizer, attack, epochs=10):
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for data, target in loader:
            data, target = data.to(device), target.to(device)

            # Generate adversarial examples
            model.eval()  # temporary evaluation mode for adversarial generation
            adv_data = attack(data, target)

            # Combine original + adversarial examples
            combined_data = torch.cat([data, adv_data])
            combined_targets = torch.cat([target, target])

            # Train model on combined dataset
            model.train()
            optimizer.zero_grad()
            output = model(combined_data)
            loss = criterion(output, combined_targets)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(loader)
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')

adversarial_training(model, train_loader, criterion, optimizer, deepfool_attack, epochs=10)

# Evaluate on original test set
accuracy_clean, precision_clean, _, _ = evaluate(model, test_loader)
print(f'Accuracy on clean data: {accuracy_clean * 100:.2f}%')

# Evaluate under DeepFool attack
adv_examples, orig_labels = generate_adversarial_examples(model, test_loader, deepfool_attack, num_samples=1000)
accuracy_adv, precision_adv, _, _ = evaluate_model_on_adversarial(model, adv_examples, orig_labels)

print(f'Accuracy after DeepFool attack: {accuracy_adv * 100:.2f}%')

# Additional adversarial attacks
attacks = {
    'FGSM': torchattacks.FGSM(model, eps=0.2),
    'PGD': torchattacks.PGD(model, eps=0.2, alpha=0.01, steps=40),
    'DeepFool': torchattacks.DeepFool(model, steps=10),
}

# Evaluate each attack
plt.figure(figsize=(10, 6))
perturbation_bins = np.linspace(0, 5, 15)

for name, attack in attacks.items():
    bins, accs = perturbation_vs_accuracy(model, test_loader, attack, perturbation_bins)
    plt.plot(bins, accs, marker='o', label=name)

# Final plot
plt.xlabel('Perturbation Magnitude (L2-norm)')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy vs. Perturbation Magnitude (Robust MLP)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()